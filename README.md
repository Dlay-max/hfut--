# hfut领域综合设计
老人人生简历生成（随便水水）

## 说明

### 环境

* python3.7

使用终端在根目录下

```bash
pip install -r requirements.txt
```

### 使用

安装好依赖后，在终端中

```bash
cd ./core  #进入到core目录中
python ./generate.py  #运行项目
```

用户在输入框中输入老人回忆录的网址（https://laonian.rednet.cn/channel/29008.html），然后点击生成按钮，系统就会自动爬取回忆录，然后提取关键信息（时间、地点、人物），并写入文件。最后，将原文与概括结果一同输出进行对比。

同时，用户也可以点击左上角的文件按钮，选择正确的文件打开后，系统同样会自动提取并生成结果。

### 参考

主要参考了以下两个项目：

* [SeanLee97/xmnlp: xmnlp：提供中文分词, 词性标注, 命名体识别，情感分析，文本纠错，文本转拼音，文本摘要，偏旁部首，句子表征及文本相似度计算等功能 (github.com)](https://github.com/SeanLee97/xmnlp)

* [pingyuan2016/word2vec_textrank: 从中文文本中自动提取摘要 (github.com)](https://github.com/pingyuan2016/word2vec_textrank)

## 问题描述

互联网存在大量个人传记或个人回忆录，这些材料通过篇幅过长，不利于信息的快速获取。本题旨在设计并实现老人人生简历快速自动生成系统。

## 实现要求

（1）==爬取==这些传记或回忆录，自动==抽取==其中的关键事件（事件包含：时间、地点、相关人物、事件描述等元素），然后按照时间排序；

（2）生成个人的人生简历，帮助他人==快速了解==此人的人生概况。

## 分析

题目要求大概可以分成两个方面，同时也对应两种技术栈，分别是爬虫与NLP

* 爬虫

首先是爬虫技术。题目要求我们搜集老人的人生传记或者回忆录，这是一切任务的数据基础；然后对于搜集到的数据，很明显会有很多带有干扰性质的脏数据，这就要求我们在爬取到数据之后应该对数据进行清洗，去除掉这些脏数据，存储到文件中方便之后的文本分析与处理

* NLP

有了爬取到的数据作为基础，接下来就是对文本进行分析。基于我自己对NLP技术的了解，我认为这个题目中的文本分析要求可以分为两类：一类是命名实体识别（NER），另一类是文本摘要。其中，第二类的文本摘要有两种实现方式，分别是提取式与生成式。这里我选择了较为简单的提取式

## 原理

* ==**爬虫**==

网络爬虫是一种自动化工具，用于从互联网上获取信息，其应用比较简单，这里对实现就不过多赘述而只是简单介绍一下原理：

1. **URL获取：** 爬虫首先从一个或多个初始的URL开始，这些URL通常是爬虫要访问的网页的入口。
2. **发送请求：** 爬虫通过HTTP或HTTPS协议向目标URL发送请求。这个请求通常是一个GET请求，但也可能是其他类型的请求，例如POST。
3. **获取响应：** 服务器收到请求后，会返回一个HTTP响应。响应中包含了网页的内容，通常是HTML格式的文本，也可能包含其他类型的数据，如图片、视频等。
4. **解析内容：** 爬虫使用解析器（如BeautifulSoup、lxml等）对响应的内容进行解析，提取其中的信息，例如链接、文本、图片等。

* **==命名实体识别==**

命名实体识别（Named Entity Recognition，简称NER）是自然语言处理（NLP）中的一项重要任务，其目标是从文本中识别并分类出具有特定意义的实体，这些实体可以是具体的名词，如人名、地名、组织机构名，也可以是时间、日期、百分比等具有特定语义的词汇。NER 的主要目的是从非结构化的文本中抽取结构化信息，帮助计算机理解文本中实体的上下文关系。

NER 的应用非常广泛，包括信息检索、问答系统、机器翻译、自动摘要、情感分析等领域。以下是命名实体识别的一些关键概念和原理：

1. **命名实体的类型**

NER 主要识别文本中的实体，并将其分类为不同的类型。常见的命名实体类型包括：

* **人名（Person）：** 识别文本中的个体名字。

- **地名（Location）：** 识别文本中的地理位置。
- **组织机构名（Organization）：** 识别文本中的公司、学校等组织机构。
- **日期（Date）：** 识别文本中的日期信息。
- **时间（Time）：** 识别文本中的时间信息。
- **货币（Money）：** 识别文本中的货币金额。
- **百分比（Percentage）：** 识别文本中的百分比信息。

2. **命名实体识别的方法**

NER 的方法主要分为规则驱动和基于机器学习的两类。

- **规则驱动方法：** 基于手工设计的规则来识别命名实体。这些规则可以基于词法、句法、语法等特征，但通常对于复杂的语境难以适应。
- **基于机器学习的方法：** 利用训练数据，通过机器学习算法从数据中学习命名实体的模式。常用的机器学习方法包括统计模型（如隐马尔可夫模型、最大熵模型）和深度学习模型（如循环神经网络、长短时记忆网络、Transformer）。

3. **NER 的处理流程**

NER 的处理流程一般包括以下步骤：

(1). **分词（Tokenization）：** 将输入文本切分成一个个单词或子词。

(2). **特征提取（Feature Extraction）：** 对每个词生成一系列特征，如词性、词形、上下文等。

(3). **标注数据（Labeling）：** 根据已知的训练数据，对每个词进行命名实体的标注。

(4). **训练模型（Model Training）：** 使用带有标注的训练数据训练命名实体识别模型。

(5). **预测（Prediction）：** 对新的文本应用训练好的模型，识别命名实体。

4. **常用的命名实体识别工具**

在NLP领域，有一些常用的工具和库可以用于命名实体识别，包括：

**spaCy：** 一个Python库，提供了高效的命名实体识别功能。

**NLTK（Natural Language Toolkit）：** 一个广泛用于处理人类语言数据的Python库。

**Stanford NER：** 由斯坦福大学开发的工具，采用基于条件随机场（CRF）的方法。

**LTP（Language Technology Platform）：** 哈工大社会计算与信息检索研究中心开发的中文自然语言处理工具包。

* ==**文本摘要**==

文本摘要（Text Summarization）是自然语言处理（NLP）领域中的一项关键任务，其目标是从原始文本中提取或生成一个简洁、概括性的摘要，捕捉文本中的主要信息，而忽略次要细节。文本摘要可以大大减少信息量，提供用户更快速、有效地理解文本主旨的方式。文本摘要广泛应用于新闻摘要、文档总结、自动化报告生成等场景。

**文本摘要的两种主要方法**

1. **抽取式文本摘要（Extractive Summarization）：** 这种方法直接从原文中选择最具代表性的句子、短语或单词，组成摘要。通常，这些被选取的片段是原文中出现频率较高、信息量较大的部分。抽取式方法的优点在于生成的摘要保留了原文的一些原汁原味，但缺点在于可能会导致一些不连贯的问题。
2. **生成式文本摘要（Abstractive Summarization）：** 这种方法则使用自然语言生成技术，根据原文的语义生成新的句子，形成摘要。生成式摘要通常更富有创造性，能够以一种新的方式表达原文的含义。然而，生成式摘要也面临着语法流畅性和准确性的挑战。

**文本摘要的处理流程**

文本摘要的处理流程一般包括以下步骤：

1. **分词（Tokenization）：** 将输入文本划分为一个个单词或子词。
2. **句子划分（Sentence Segmentation）：** 将文本划分为句子。
3. **特征提取（Feature Extraction）：** 对每个单词或句子提取特征，通常包括词频、TF-IDF（词频-逆文档频率）等。
4. **建模（Modeling）：** 根据特征，使用机器学习或深度学习模型进行建模。对于抽取式摘要，可以使用排序模型，对句子或单词进行重要性排序；对于生成式摘要，可以使用序列到序列模型（Seq2Seq）等。
5. **生成摘要（Summary Generation）：** 根据模型的输出，生成摘要。在生成式方法中，这通常包括语言生成模型生成新的句子。

**常用的文本摘要方法和工具**

1. **TF-IDF 方法：** 基于词频-逆文档频率的方法，抽取最重要的词语或短语作为摘要。
2. **TextRank 算法：** 类似于谷歌的 PageRank 算法，通过图的链接结构对句子进行排序，选取重要句子。
3. **Seq2Seq 模型：** 基于循环神经网络（RNN）或变换器（Transformer）的生成式模型，对句子进行生成。
4. **BERTsum：** 基于预训练的 BERT 模型进行微调，用于生成更高质量的抽取式摘要。
5. **spaCy 和 NLTK：** 提供了一些用于文本摘要的工具和算法，可以用于基本的抽取式文本摘要。

## 实现步骤

在我的计划中，该项目的规划主要分为以下几步：

### 1. 数据爬取和预处理

首先，需要选择合适的网站或数据库，爬取老人的传记或回忆录数据。这里我找到的网站主要是：[记忆库_老年频道 (rednet.cn)](https://laonian.rednet.cn/channel/29008.html)

然后使用 Python 中的爬虫框架——BeautifulSoup，进行网页数据抓取。前提是确保遵守网站的使用政策和法规。

将抓取到的数据进行预处理，清洗掉不需要的标签、广告等信息。将文本内容按回忆事件进行分段，每段表示一个事件。

### 2. 事件关键信息抽取

使用自然语言处理（NLP）工具，来对每个事件的文本进行分析和抽取关键信息。主要通过命名实体识别（NER）等技术来定位和抽取一些关键信息：时间、地点、人物等等。

### 3.事件关键概括

对分段整理好的信息，使用NLP中的文本摘要技术简单提取每个事件的关键句，对事件进行高度概括。

### 4. 界面设计和交互

设计一个用户友好的界面，让用户输入网页网址，然后调用系统自动生成人生简历，帮助他人快速了解此人的人生概况。

### 5. 测试和优化

对系统进行测试，确保生成的人生简历尽量准确、清晰且易于理解。根据测试结果进行系统的优化和改进。

## 最后：

由于我自身能力不足与设备问题，主要借助的是一些NLP现有的工具包，实现的效果并不够完善准确，无法完美实现题目的要求
